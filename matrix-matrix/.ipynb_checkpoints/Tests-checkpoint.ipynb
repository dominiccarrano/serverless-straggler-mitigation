{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests for `gemm_recompute` and `gemm_coded`\n",
    "\n",
    "Suite of test cases for the matrix multiplication functions for various inputs (square and nonsquare of various sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matmul import *\n",
    "\n",
    "# Library function numpywren.BigMatrix.numpy uses some deprecated syntax; \n",
    "# want to avoid flooding the output when calling this\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_randn_block(id, X):\n",
    "    \"\"\"Draw data randomly from a standard normal distribution.\"\"\"\n",
    "    X.put_block(np.random.randn(X.shard_sizes[0], X.shard_sizes[1]), *id)\n",
    "    return 0\n",
    "\n",
    "def randn_bigmtx(RB, CB, SS):\n",
    "    \"\"\"Make a dense (RB x CB) blocked numpywren.matrix.BigMatrix with SS x SS blocks.\"\"\"\n",
    "    num_rows, num_cols = int(RB * SS), int(CB * SS)\n",
    "    X_sharded = matrix.BigMatrix(\"X_sharded{0}_{1}_{2}\".format(num_rows, num_cols, SS), \\\n",
    "                                 shape=(num_rows, num_cols), \\\n",
    "                                 shard_sizes=[SS, SS], \\\n",
    "                                 autosqueeze=False, \\\n",
    "                                 write_header=True)        \n",
    "    if len(X_sharded.block_idxs_not_exist) > 0:\n",
    "        pwex = pywren.lambda_executor()\n",
    "        futures = pwex.map(lambda idx: make_randn_block(idx, X_sharded), X_sharded.block_idxs_not_exist)\n",
    "        pywren.wait(futures, ALL_COMPLETED)\n",
    "    return X_sharded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for AA.T\n",
    "A = randn_bigmtx(2, 2, 512)\n",
    "A_local = A.numpy()\n",
    "C = A_local.dot(A_local.T)\n",
    "C_coding, _, _, _ = gemm_coded(A, A, blocks_per_parity=2, s3_key=\"coded_out\")\n",
    "C_recomp, _, _ = gemm_recompute(A, A, thresh=.7, s3_key=\"recomp_out\")\n",
    "assert np.allclose(C_coding.numpy(), C)\n",
    "assert np.allclose(C_recomp.numpy(), C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for AB.T with square A and nonsquare B\n",
    "A = randn_bigmtx(2, 2, 128)\n",
    "B = randn_bigmtx(4, 2, 128)\n",
    "\n",
    "A_local, B_local = A.numpy(), B.numpy()\n",
    "C = A_local.dot(B_local.T)\n",
    "C_coding, _, _, _ = gemm_coded(A, B, blocks_per_parity=2, s3_key=\"coded_out\")\n",
    "C_recomp, _, _ = gemm_recompute(A, B, thresh=.7, s3_key=\"recomp_out\")\n",
    "assert np.allclose(C_coding.numpy(), C)\n",
    "assert np.allclose(C_recomp.numpy(), C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for AB.T with nonsquare A and nonsquare B\n",
    "A = randn_bigmtx(3, 6, 64)\n",
    "B = randn_bigmtx(9, 6, 64)\n",
    "\n",
    "A_local, B_local = A.numpy(), B.numpy()\n",
    "C = A_local.dot(B_local.T)\n",
    "C_coding, _, _, _ = gemm_coded(A, B, blocks_per_parity=3, s3_key=\"coded_out\")\n",
    "C_recomp, _, _ = gemm_recompute(A, B, thresh=.7, s3_key=\"recomp_out\")\n",
    "assert np.allclose(C_coding.numpy(), C)\n",
    "assert np.allclose(C_recomp.numpy(), C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
